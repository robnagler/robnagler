---
redirect_from: "/2008/10/24/BookReview-The-Emotion-Machine.html"
layout: post
title: "BookNotes: The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind"
date: 2008-10-24T12:00:00Z
---
By Marvin Minsky, Simon & Schuster, November 7, 2006, 978-0743276634

This is my first Marvin Minksy book.  I've read about his ideas,
and probably read a few articles by him.  The book is well written
and covers many ideas on how the brain might work.  It took me a while
to read it, because there was so much information.

He uses a platontic-dialectic style by injecting rhetorical
comments/questions by characters (Citizen, Student, etc.).  The device
worked ok in this book, but I found it a bit tedious.  Perhaps I'd
prefer a simple rhetorical question than the text interspersed with
fictional character comments.


> [p5] Citizen: I still think your view of emotions ignores too
> much. For example, emotional states like fear and disgust involve the
> body as well as the brain, as when we feel discomfort in the chest or
> gut, or palpitations of the heart, or when we feel faint or tremble or
> sweat.



> I agree that this view may seem too extreme-but sometimes, to explore
> new ideas, we need to set our old ones aside, at least
> temporarily. For example, in the most popular view, emotions are
> deeply involved with our bodies' conditions. However, Chapter 7 will
> take the opposite view, by regarding our body parts as resources that
> our brains can use to change [p6] (or main rain) their mental stares!
> For example, you sometimes Can make yourself persist at a plan by
> maintaining a certain facial expression.



> [p6] Accordingly, when we design machines to mimic our minds-that is,
> to create Artificial Intelligences-we'll need to make sure that those
> machines, root, are equipped with sufficient diversity:  



> If a program works in only one way, then it gets stuck when that
> method fails. But a program that has several ways to proceed could
> then switch to some other approach, or search for a suitable
> substitute.  



> This idea is a central theme of this book-and it is firmly opposed to
> the popular view that each person has a central core-some sort of
> invisible spirit or self-from which all their mental abilities
> originate. For that seems a demeaning idea-that all our virtues are
> secondhand-or that we deserve no credit for our accomplishments,
> because they come to us as gifts from some other source. Instead, I
> see our dignity as stemming from what we each have made of ourselves:
> a colossal collection of different ways to deal with different
> situations and predicaments. It is that diversity that distinguishes
> us from most of the other animals-and from all the machines that we've
> built in the past-and every chapter of this book will discuss some of
> the sources of our uniquely human resourcefulness.  


 I enjoy the concept of suitcase-like words.  It's important to be
able to pick apart the words we use every day as if they mean one
thing; they don't.  Words are complex conceptions.  Understanding
words requires talking about them in a particular context, and even
then, we have different connotations for the same word.


> [p97] All this should lead us to conclude that consciousness is a
> suitcase-like word that we use to refer to many different mental
> activities, which don't have a single cause or origin-and, surely,
> this is why people have found it so hard to "understand what
> consciousness is." The trouble was that they tried to pack into a
> single box all the products of many processes that go on in different
> parts of our brains-and this produced a problem that will remain
> unsolvable until we find ways to chop it up. However, once we imagine
> a mind as made of smaller parts, we can replace that single, big
> problem by many smaller, more solvable ones-which is just what this
> chapter will try to do.  


 The following is a strong argument for testing as a critical part
of software evolution.


> [p105] The same sort of constraint also seems to apply whenever we try
> to improve the performance of any large system. For example, after
> every change we make in an existing computer program, we usually find
> that this has created additional bugs-and then we need to make yet
> more corrections. In fact, many computer systems eventually become so
> ponderous that their further development Stops, because their
> programmers can no longer keep track of what all the previous
> programmers did.  



> Similarly, it appears that our brains result from processes in which
> each new part in based on some older designs, but also includes
> exceptions to it. Indeed, I suspect that large parts of our brains
> work mainly to correct mistakes that other parts make-and this is
> surely one reason why the subject of human psychology has become so
> hard. We can expect to discover neat rules and laws that partly
> explain many aspects of how we think. However, every such "law of
> thought" will also need a sizable list of exceptions to it. So
> psychology will never be much like physics, in which we frequently
> find "unified theories" that work flawlessly.  



> [p112] Aaron Sloman 1994: "People are too impatient. They want a three-line
> definition of consciousness and a five-line proof that a computational
> system can or cannot have consciousness. And they want it today. They
> don't want to do the hard work of unraveling complex and muddled
> concepts that we already have, and exploring new variants that could
> emerge from precisely specified architectures for behaving systems."



> [p180] I do not mean to dismiss all prospects of building a
> baby-machine, but I suspect that any such system would develop too
> slowly unless (or until) it was equipped with adequate ways to
> represent knowledge (see Chapter 8). In any case, iv seems fairly
> clear that human brains are innately equipped with highly developed
> ways to learn (some of which don't start to operate until long after
> birth). The researchers who have tried to build such machines have
> used quire a few ingenious schemes, but it seems to me that each of
> those machines got stuck because of not having ways to overcome one or
> more problems like these:  



> [p181] The Optimization Paradox: The better a system already works,
> the more likely each change will make it worse-so it gets more
> difficult for it to find more ways to improve itself  



> The Investment Principle: The better a certain process works, the more
> we will tend to rely on it, and the less we will be further inclined
> to develop new alternatives--especially when a new technique won't
> yield good results until you become proficient with it.  



> The Complexity Barrier: The more that the parts of a system interact,
> the more likely each change will have unexpected side effects.  



> Evolution is often described as a process of selecting beneficial
> changes but most of evolution's work involves rejecting changes that
> have bad effects! This surely is why most species evolve to occupy
> narrow, specialized niches that are bounded by all sorts of hazards
> and traps. It is not often recognized that while genetic evolution can
> "learn" to avoid the most common kinds of mistakes, it is virtually
> incapable of learning large numbers of very uncommon mistakes. Indeed,
> only a few "higher animals" have escaped from this by evolving
> language-like systems through which they can inform their descendants
> about accidents that happened to some of their ancestors' relatives.  



> [p185] Alan Watts 1960: "No one imagines that a symphony is supposed
> to improve in quality as it goes along, at that the whole object of
> playing it is to teach the finale. The point of music is discovered in
> every moment of playing and listening to it. It is the same, I feel,
> with the greater part of our lives, and if we are unduly absorbed in
> improving them we may forget altogether to live them."



> [p206] Douglas Lenat 1997: "Analogy works because there is a lot of
> common causality in the world, common causes which lead to an overlap
> between two systems, between two phenomena or whatever. We, as human
> beings, can only observe a tiny bit of that overlap; a tiny bit of
> what is going on at this level of the world .... [So] whenever we find
> an overlap at this level, it is worth seeing if in fact there are
> additional overlap features, even though we do not understand the
> cause or causality behind it.



> [p210] Decisiveness: We often speak of "making a choice," as though
> this were a deliberate act. However, that "action" may. in fact, be
> nothing more than the moment at which you stopped some process that
> was comparing alternatives-and then, by default, you simply adopted
> the one that was then at the top of some list. In such a case, a
> person may speak of using "free will"-but an observer could also see
> it as nothing more than a sort of admission (or even a boast) that one
> does not have a clear idea about what mental process produced that
> result.  



> [p239] Poincare 1913: "What is it indeed that gives us the feeling of
> elegance in a solution, in a demonstration? It is the harmony of the
> diverse parts, their symmetry, their happy balance; it is all that
> introduces order, all that gives unity, that permits us to see clearly
> and to comprehend at once both the ensemble and the details."



> [p257] If you "understand" something in only one way, then you
> scarcely understand it at all-because when something goes wrong,
> you'll have no place to go. Bur if you represent something in several
> ways, then when one method fails, you can switch to another. Thar way,
> you can rum things around in your mind to see them from different
> points of view-until you find one that works for you!  



> [p271] As children, we not only learn particular things, but we also
> acquire new thinking techniques. However, no infant could ever invent,
> by itself, enough co develop an adult intelligence. So perhaps our
> most important skill is how we learn, not only from having our own
> experiences, but also from being told things by other people.



> [p275] "The best way to have a good idea is to have lots of ideas."
> -- Linus Pauling



> We admire our Einsteins, Shakespeares, and Beethovens-and many people
> insist that their accomplishments ate inspired by "gifts" that cannot
> be explained. If so, then machines could never do such things because
> (at least, in that popular view) no machine could hold any such
> mysteries.  



> However, when one has the fortune to meet one of those persons whom we
> portray as "great," one finds no single, unusual trait that seems to
> account for their excellence. Instead (at least it seems to me), all
> that we find are unusual combinations of otherwise common
> ingredients. I.  



> They are highly proficient in their fields. (But by itself we just
> call this expertise.)  



> They have more than usual self-confidence. (Hence better to withstand
> the scorn of peers.)  



> They often persist where others would quit. (But others may just call
> this stubbornness.)  



> They accumulate more Ways to Think. (But then they'll need better ways
> to switch.)  



> They habitually think in novel ways. (But so do others, albeit less
> frequently.)  



> They have better systems for self-control. (So they waste less time on
> irrelevant goals.)  



> [p278] This section has mainly aimed to explain why some people get
> better ideas than others do. But what if we change that question to
> ask, instead, what could make one person become less resourceful than
> another one? Here is one process that could tend to limit the growth
> of ones versatility:  



> The Investment Principle: If you know two different ways to achieve
> the same goal, you'll usually start with the method that you know
> best. Then, over time, that method may gain so much additional
> strength that you'll tend to use it exclusively---even if you have
> been told that the other technique is the better one.  



> [p328] For example, whenever something touches your hand, it seems to
> you that you instantly sense that you have felt a touch on your
> hand-and that this happened immediately, without any complex
> processing. Similarly, when you look at a color and sense that it's
> red, no intermediate steps seem to intervene-and so you can find
> nothing to say about it. Surely this is at least partly why so many
> philosophical thinkers conclude that there can be no "mechanical"
> explanation of why different stimuli seem each to have particular
> qualities: they simply have not worked hard enough to imagine adequate
> models of those processes; instead, they mainly attempted to show that
> no such models would ever be possible.  



